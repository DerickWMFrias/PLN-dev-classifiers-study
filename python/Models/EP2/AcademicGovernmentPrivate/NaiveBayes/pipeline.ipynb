{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45aeab7b-3cab-4ea2-ad18-8b335f840025",
   "metadata": {},
   "source": [
    "# Pipelines de treinamento: NaiveBayes\n",
    "\n",
    "Esse notebook contém as pipelines de treinamento usadas na obtenção do melhor modelo classificador do problema desenvolvido no EP2.\n",
    "\n",
    "O modelo NaiveBayes aceita diversas parametrizações diferentes - veja documentação: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB - aqui exploramos duas: *alpha* e *force-alpha*. \n",
    "\n",
    "As pipelines treinadas são estratificadas em **features + MultinomialNB:force-alpha**.  \n",
    "Isto quer dizer: existe uma pipeline para cada par de *feature* e *force-alpha* aqui explorados.   \n",
    "\n",
    "As **features** que exploramos são:  \n",
    "\n",
    "1. Bag of Words  \n",
    "2. TF/TF-IDF  \n",
    "3. CHAR NGrams  \n",
    "4. Embeddings\n",
    "\n",
    "Os **modelos de embeddings** que exploramos aqui são:  \n",
    "\n",
    "1. BAAI bge-3\n",
    "2. Google Gemma 300m \n",
    "\n",
    "PS: Os embeddings Gemma 300m eu ainda NÃO CONSEGUI GERAR. Então, não precisa testar a parte que roda com eles no EP.\n",
    "\n",
    "Você pode encontrar uma execução já parametrizada do melhor modelo encontrado por essas pipelines no notebook model.ipynb, **que é nossa versão de entrega do EP2**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66daa92-d19a-4295-89b2-92668e6461a7",
   "metadata": {},
   "source": [
    "## Bootstrap Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ebad25b-fab5-4e0e-9ee1-722c3ac1031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df84faea-b91f-430f-a62d-3018d3003183",
   "metadata": {},
   "source": [
    "### Teste de importação: Lib.utils do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3672f7-182a-4a38-81ce-3d1a51888a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO!\n"
     ]
    }
   ],
   "source": [
    "filedir = Path(os.getcwd())\n",
    "base_path = filedir.resolve().parents[3]\n",
    "sys.path.append(str(base_path))\n",
    "\n",
    "from Lib.utils import printhello\n",
    "printhello()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23816935",
   "metadata": {},
   "source": [
    "## Configura variáveis de execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e29f38-21fb-46e4-930f-3acea82caf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to csv input is:  ../../../../Traindata/EP2/ep2-train.csv\n"
     ]
    }
   ],
   "source": [
    "sep = \";\"\n",
    "dec = \",\"\n",
    "quotech = \"\\\"\"\n",
    "encoding = \"latin-1\"\n",
    "\n",
    "\n",
    "EP_dir = \"EP2\"\n",
    "CSV_input_name = \"ep2-train.csv\"\n",
    "path_to_archive = f\"../../../../Traindata/{EP_dir}/{CSV_input_name}\"\n",
    "\n",
    "\n",
    "do_print = True\n",
    "if do_print:\n",
    "    print(f\"Path to csv input is:  {path_to_archive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7249cf-a74e-4c47-b3a6-bce9743358dd",
   "metadata": {},
   "source": [
    "### Configure variáveis de reprodutibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0116d0-3657-4ab9-a8b8-8dcf33211f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd5165-ce97-41ab-8f0e-06bc37812cf2",
   "metadata": {},
   "source": [
    "### Lista de melhores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73350f24-eb92-4ae4-967e-1dd120698d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d1b5e-f486-4912-af07-a2dcaa2bb6ea",
   "metadata": {},
   "source": [
    "## Pré-tratamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbef0f3-fa62-4170-96a2-161889bc8067",
   "metadata": {},
   "source": [
    "### Importar dados do csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ab2442-23af-4f5b-9c39-8420e67dfd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43678, 2)\n",
      "Index(['req_text', 'profession'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_archive, na_values=['na'],\n",
    "sep=sep,\n",
    "decimal=dec,\n",
    "quotechar=quotech,\n",
    "encoding=encoding,\n",
    "encoding_errors='strict')\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6c927-5bdf-4493-ac40-ceec3cba4a01",
   "metadata": {},
   "source": [
    "### Embaralhamento dos dados\n",
    "\n",
    "O .csv de entrada tem alto ordenamento dos inputs por classe. Carregá-los dessa maneira nos modelos p/ treinamento introduz viés, então é preciso embaralhar os dados para garantir randomicidade. \n",
    "As classes em sklearn.model_selection - como a StratfiedKFold usada mais a frente - implementam parâmetro shuffle=\"\", que pode ser passado como True para embaralhar mais os dados.\n",
    "\n",
    "Note que é importante também garantir a reprodutibilidade do embaralhamento, especificando um valor hardcoded (Neste caso random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649a696-035d-43ce-9161-d85188248c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape antes do shuffle: (43678, 2)\n",
      "Shape depois do shuffle: (43678, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape antes do shuffle:\", df.shape)\n",
    "\n",
    "df = df.sample(frac=1, random_state=random_state).reset_index(drop=True) #NAO MUDE random_state, essa variavel DEVE valer 12345, ou QUEBRARÁ REPRODUTIBILIDADE dos experimentos\n",
    "\n",
    "print(\"Shape depois do shuffle:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ba18f-21f5-4950-a42f-9174b490135b",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164713c-9790-4953-981a-fde31e01f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lib.utils import clean_text\n",
    "#def clean_text(text, do_lowercase: bool, rem_emails: bool, rem_urls: bool, normalize_whitespaces: bool):\n",
    "\n",
    "df['req_text_cleaned'] = df['req_text'].apply(lambda row_text: clean_text(\n",
    "        row_text, \n",
    "        do_lowercase=True, \n",
    "        rem_emails=True, \n",
    "        rem_urls=True, \n",
    "        normalize_whitespaces=True\n",
    "    ))\n",
    "\n",
    "df['req_text'] = df['req_text_cleaned']\n",
    "df = df.drop(columns=['req_text_cleaned']) # Remove a coluna temporária"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b69fbf",
   "metadata": {},
   "source": [
    "# Treino dos modelos NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf4b89",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26389c9b",
   "metadata": {},
   "source": [
    "## Training Features: Bag of Words, TF-IDF, Word NGram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ec62f",
   "metadata": {},
   "source": [
    "### Disable Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a74c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignora warnings de ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Ignora UserWarnings específicos de l1_ratio etc\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a90a2f",
   "metadata": {},
   "source": [
    "### Feature: Bag of words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29d357",
   "metadata": {},
   "source": [
    "#### Definição da Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c4a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('kbest', SelectKBest(score_func=chi2)),\n",
    "    ('classifier', MultinomialNB()),\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ba93e",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_parameters_T = {\n",
    "    'kbest__k': [50, 100, 500, 1500, 4000, 10000, 20000, 'all'],\n",
    "    'classifier__force_alpha': [True],\n",
    "    'classifier__alpha': [1.0, 0.5, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8641a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_classifier_T = GridSearchCV(BoW_pipeline, BoW_parameters_T, \n",
    "                                       cv=10, n_jobs=-1, scoring=\"accuracy\", verbose=1, error_score = np.nan)\n",
    "BoW_classifier_T.fit(df[\"req_text\"].fillna(\"\"), df[\"profession\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", BoW_classifier_T.best_score_)\n",
    "print(\"Melhores parâmetros:\", BoW_classifier_T.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"BoW\",\n",
    "    \"force-alpha\": True,\n",
    "    \"accuracy\": BoW_classifier_T.best_score_,\n",
    "    \"params\": BoW_classifier_T.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058fdce3",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_parameters_F = {\n",
    "    'kbest__k': [50, 100, 500, 1500, 4000, 10000, 20000, 'all'],\n",
    "    'classifier__force_alpha': [False],\n",
    "    'classifier__alpha': [1e-10, 1e-11, 1e-12, 1e-13, 0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_classifier_F = GridSearchCV(BoW_pipeline, BoW_parameters_F, \n",
    "                                       cv=10, n_jobs=-1, scoring=\"accuracy\", verbose=1, error_score = np.nan)\n",
    "BoW_classifier_F.fit(df[\"req_text\"].fillna(\"\"), df[\"profession\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3cbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", BoW_classifier_F.best_score_)\n",
    "print(\"Melhores parâmetros:\", BoW_classifier_F.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"BoW\",\n",
    "    \"force-alpha\": False,\n",
    "    \"accuracy\": BoW_classifier_F.best_score_,\n",
    "    \"params\": BoW_classifier_F.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37792143",
   "metadata": {},
   "source": [
    "### Feature: TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da5cfd",
   "metadata": {},
   "source": [
    "#### Definição da Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415afb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('kbest', SelectKBest(score_func=chi2)),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9c24c",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cde7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_parameters_T = {\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'kbest__k': [50, 100, 500, 1500, 4000, 10000, 20000, 'all'],\n",
    "    'classifier__force_alpha': [True],\n",
    "    'classifier__alpha': [1.0, 0.5, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42911f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_classifier_T = GridSearchCV(TF_pipeline, TF_parameters_T, \n",
    "                                       cv=10, n_jobs=-1, scoring=\"accuracy\", verbose=1, error_score = np.nan)\n",
    "TF_classifier_T.fit(df[\"req_text\"].fillna(\"\"), df[\"profession\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", TF_classifier_T.best_score_)\n",
    "print(\"Melhores parâmetros:\", TF_classifier_T.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"TF\",\n",
    "    \"force-alpha\": True,\n",
    "    \"accuracy\": TF_classifier_T.best_score_,\n",
    "    \"params\": TF_classifier_T.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca31e5",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc956a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_parameters_F = {\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'kbest__k': [50, 100, 500, 1500, 4000, 10000, 20000, 'all'],\n",
    "    'classifier__force_alpha': [False],\n",
    "    'classifier__alpha': [1e-10, 1e-11, 1e-12, 1e-13, 0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_classifier_F = GridSearchCV(TF_pipeline, TF_parameters_F, \n",
    "                                       cv=10, n_jobs=-1, scoring=\"accuracy\", verbose=1, error_score = np.nan)\n",
    "TF_classifier_F.fit(df[\"req_text\"].fillna(\"\"), df[\"profession\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99cb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", TF_classifier_F.best_score_)\n",
    "print(\"Melhores parâmetros:\", TF_classifier_F.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"TF\",\n",
    "    \"force-alpha\": False,\n",
    "    \"accuracy\": TF_classifier_F.best_score_,\n",
    "    \"params\": TF_classifier_F.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883276ca",
   "metadata": {},
   "source": [
    "### Feature: CHAR Ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511faf4",
   "metadata": {},
   "source": [
    "#### Definição da Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGram_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('kbest', SelectKBest(score_func=chi2)),\n",
    "    ('classifier', MultinomialNB()),\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55f508",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fb7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_NGram_parameters_T = { \n",
    "    'vect__ngram_range': [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12)],\n",
    "    'vect__analyzer': [\"char\", \"char_wb\"],\n",
    "    'kbest__k': [100, 200, 750, 4000, 10000, 25000],\n",
    "    'classifier__force_alpha': [True],\n",
    "    'classifier__alpha': [1.0, 0.5, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_NGram_classifier_T = GridSearchCV(NGram_pipeline, CHAR_NGram_parameters_T, \n",
    "                                       cv=10, n_jobs=2, scoring=\"accuracy\", verbose=1, error_score = np.nan)\n",
    "CHAR_NGram_classifier_T.fit(df[\"req_text\"].fillna(\"\"), df[\"profession\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ee04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", CHAR_NGram_classifier_T.best_score_)\n",
    "print(\"Melhores parâmetros:\", CHAR_NGram_classifier_T.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"CHAR-NGram\",\n",
    "    \"force-alpha\": True,\n",
    "    \"accuracy\": CHAR_NGram_classifier_T.best_score_,\n",
    "    \"params\": CHAR_NGram_classifier_T.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078abfa",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19964cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_NGram_parameters_F = { \n",
    "    'vect__ngram_range': [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9), (10, 10), (11, 11), (12, 12)],\n",
    "    'vect__analyzer': [\"char\", \"char_wb\"],\n",
    "    'kbest__k': [100, 200, 750, 4000, 10000, 25000],\n",
    "    'classifier__force_alpha': [False],\n",
    "    'classifier__alpha': [1e-10, 1e-11, 1e-12, 1e-13, 0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf698100",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_NGram_classifier_F = GridSearchCV(NGram_pipeline, CHAR_NGram_parameters_F, \n",
    "                                       cv=10, n_jobs=2, scoring=\"accuracy\", verbose=1, error_score = np.nan)\n",
    "CHAR_NGram_classifier_F.fit(df[\"req_text\"].fillna(\"\"), df[\"profession\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", CHAR_NGram_classifier_F.best_score_)\n",
    "print(\"Melhores parâmetros:\", CHAR_NGram_classifier_F.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"CHAR-NGram\",\n",
    "    \"force-alpha\": False,\n",
    "    \"accuracy\": CHAR_NGram_classifier_F.best_score_,\n",
    "    \"params\": CHAR_NGram_classifier_F.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39a722",
   "metadata": {},
   "source": [
    "## Training Features: Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b14d1",
   "metadata": {},
   "source": [
    "### Algoritmo & parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb40169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configurar o GridSearchCV diretamente no classificador KNN (sem o Pipeline wrapper)\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "nb_parameters_T = {\n",
    "    'force_alpha': [True],\n",
    "    'alpha': [1.0, 0.5, 0.1],\n",
    "}\n",
    "\n",
    "nb_parameters_F = {\n",
    "    'force_alpha': [False],\n",
    "    'alpha': [1e-10, 1e-11, 1e-12, 1e-13, 0],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff39e5f",
   "metadata": {},
   "source": [
    "### Feature: Embeddings BAAI-bge-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0fb4e",
   "metadata": {},
   "source": [
    "#### Importação dos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d3935-6ed3-4c7a-8b6d-fe8e1924706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando BAAI embeddings\n",
      "Shape dos embeddings (X): (500, 1024)\n",
      "embeddings gerados\n"
     ]
    }
   ],
   "source": [
    "# 1. Gerar os dados X e Y\n",
    "X_baai = np.load('../../Embeddings/npys/gen_baai_bge_3.ipynb')\n",
    "y_baai = df[\"profession\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408313c",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a4963",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_baai_T = GridSearchCV(nb, nb_parameters_T, \n",
    "                                       cv=10, n_jobs=-1, scoring=\"accuracy\", verbose=1, error_score=np.nan)\n",
    "# 3. Fitar (Treinar) usando os embeddings pré-calculados\n",
    "nb_baai_T.fit(X_baai, y_baai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d533b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", nb_baai_T.best_score_)\n",
    "print(\"Melhores parâmetros:\", nb_baai_T.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"embeddings baai-bge-3\",\n",
    "    \"force-alpha\": True,\n",
    "    \"accuracy\": nb_baai_T.best_score_,\n",
    "    \"params\": nb_baai_T.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede41a26",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409037a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_baai_F = GridSearchCV(nb, nb_parameters_F, \n",
    "                                       cv=10, n_jobs=-1, scoring=\"accuracy\", verbose=1, error_score=np.nan)\n",
    "# 3. Fitar (Treinar) usando os embeddings pré-calculados\n",
    "nb_baai_F.fit(X_baai, y_baai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", nb_baai_F.best_score_)\n",
    "print(\"Melhores parâmetros:\", nb_baai_F.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"embeddings baai-bge-3\",\n",
    "    \"force-alpha\": False,\n",
    "    \"accuracy\": nb_baai_F.best_score_,\n",
    "    \"params\": nb_baai_F.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9842aff",
   "metadata": {},
   "source": [
    "### Feature: Embeddings Google Gemma-300m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d265c",
   "metadata": {},
   "source": [
    "#### Importação dos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782618b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gerar os dados X e Y\n",
    "X_gemma = np.load('../../Embeddings/npys/gen_google_gemma_300m.ipynb')\n",
    "y_gemma = df[\"profession\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef972a",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95321193",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gemma_T = GridSearchCV(nb, nb_parameters_T, \n",
    "                                       cv=10, n_jobs=-1, scoring=\"accuracy\", verbose=1, error_score=np.nan)\n",
    "# 3. Fitar (Treinar) usando os embeddings pré-calculados\n",
    "nb_gemma_T.fit(X_gemma, y_gemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dbe71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", nb_gemma_T.best_score_)\n",
    "print(\"Melhores parâmetros:\", nb_gemma_T.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"embeddings google-gemma-300m\",\n",
    "    \"force-alpha\": True,\n",
    "    \"accuracy\": nb_gemma_T.best_score_,\n",
    "    \"params\": nb_gemma_T.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2928003f",
   "metadata": {},
   "source": [
    "#### Treinamento c/ force_alpha=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gemma_F = GridSearchCV(nb, nb_parameters_F, \n",
    "                                       cv=10, n_jobs=-1, scoring=\"accuracy\", verbose=1, error_score=np.nan)\n",
    "# 3. Fitar (Treinar) usando os embeddings pré-calculados\n",
    "nb_gemma_F.fit(X_gemma, y_gemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8222884",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Melhor acurácia média:\", nb_gemma_F.best_score_)\n",
    "print(\"Melhores parâmetros:\", nb_gemma_F.best_params_)\n",
    "\n",
    "best_models_list.append({\n",
    "    \"features\": \"embeddings google-gemma-300m\",\n",
    "    \"force-alpha\": False,\n",
    "    \"accuracy\": nb_gemma_F.best_score_,\n",
    "    \"params\": nb_gemma_F.best_params_,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b7d8a",
   "metadata": {},
   "source": [
    "# Seleciona melhores parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ce655",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -1\n",
    "best = 0\n",
    "for idx, candidate in enumerate(best_models_list):\n",
    "    if candidate[\"accuracy\"] > best_score:\n",
    "        best = idx\n",
    "        best_score = candidate[\"accuracy\"]\n",
    "\n",
    "print(f\"O melhor classificador encontrado pelas pipelines é -->    feature={best_models_list[best][\"features\"]} + force_alpha={best_models_list[best][\"force_alpha\"]}\\n\")\n",
    "print(f\"Melhor acucácia encontrada:  {best_models_list[best]['accuracy']}\")\n",
    "print(f\"Melhores parametros encontrados:  {best_models_list[best]['params']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
