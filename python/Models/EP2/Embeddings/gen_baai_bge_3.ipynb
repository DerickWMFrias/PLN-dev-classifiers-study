{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf8449a-14c8-4b47-830e-a70e27515361",
   "metadata": {},
   "source": [
    "# Geração de embeddings: BAAI bge-3\n",
    "\n",
    "Este notebook gera um arquivo .npy contendo embeddings - gerados a partir do modelo BAAI bge-3 - de um conjunto de textos. Para bom uso desse notebook, atente-se as informações sobre o modelo em questão.\n",
    "\n",
    "Dados do modelo BAAI bge-3:\n",
    "\n",
    "1-model_provider:\n",
    "\n",
    "2-embed_arch:\n",
    "\n",
    "3-embed_model:\n",
    "\n",
    "4-max_sequence_length (Tokens):\n",
    "\n",
    "5-n_parameters:\n",
    "\n",
    "6-embed_dimension:\n",
    "\n",
    "7-is_multilingual:\n",
    "\n",
    "8- License:\n",
    "\n",
    "9- source (HugginFace):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1c415-358a-4700-a59e-0095f10242b8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20d1f0d4-9ed7-47d5-811d-51a4ed785b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575ec36-dc71-4082-bd78-a96c3edf5809",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417fa6fb-7783-414c-9c8e-1f7fd19f8721",
   "metadata": {},
   "source": [
    "### Configura variáveis de execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaeb2741-5362-4a1a-a9f3-96e69e6bd04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to csv input is:  ../../../Traindata/EP2/ep2-train.csv\n"
     ]
    }
   ],
   "source": [
    "sep = \";\"\n",
    "dec = \",\"\n",
    "quotech = \"\\\"\"\n",
    "encoding = \"latin-1\"\n",
    "\n",
    "\n",
    "EP_dir = \"EP2\"\n",
    "CSV_input_name = \"ep2-train.csv\"\n",
    "path_to_archive = f\"../../../Traindata/{EP_dir}/{CSV_input_name}\"\n",
    "\n",
    "\n",
    "do_print = True\n",
    "if do_print:\n",
    "    print(f\"Path to csv input is:  {path_to_archive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c7fac-bfa4-40f8-bfc4-f7cfc9d2dce6",
   "metadata": {},
   "source": [
    "### Configura variáveis de reprodutibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab957f15-0f2b-45ba-873f-1693c5d11fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd3e64-3629-444b-a7a5-eab8202699f0",
   "metadata": {},
   "source": [
    "## Pré-tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e1327-91f2-4e29-8bb7-875ec63cd567",
   "metadata": {},
   "source": [
    "### Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5274bef-f46b-467c-b3c4-de8466867ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43678, 2)\n",
      "Index(['req_text', 'profession'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_archive, na_values=['na'],\n",
    "sep=sep,\n",
    "decimal=dec,\n",
    "quotechar=quotech,\n",
    "encoding=encoding,\n",
    "encoding_errors='strict')\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86bc008-8f36-4859-8f54-e5c7b6324f69",
   "metadata": {},
   "source": [
    "### Embaralhamento dos dados\n",
    "\n",
    "O .csv de entrada tem alto ordenamento dos inputs por classe. Carregá-los dessa maneira nos modelos p/ treinamento introduz viés, então é preciso embaralhar os dados para garantir randomicidade. \n",
    "As classes em sklearn.model_selection - como a StratfiedKFold usada mais a frente - implementam parâmetro shuffle=\"\", que pode ser passado como True para embaralhar mais os dados.\n",
    "\n",
    "Note que é importante também garantir a reprodutibilidade do embaralhamento, especificando um valor hardcoded (Neste caso random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4535f6ff-14d4-458e-bc6e-391bd2b2ab8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape antes do shuffle: (43678, 2)\n",
      "Shape depois do shuffle: (43678, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape antes do shuffle:\", df.shape)\n",
    "\n",
    "df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "print(\"Shape depois do shuffle:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310579b-b65a-4db5-9503-d61824925206",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85bd3172-431b-4f4e-81ff-c266db28ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Encontra o diretório atual do notebook\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 2. Navega 3 níveis acima para encontrar a pasta raiz que contém 'Lib'\n",
    "# Ajuste o número de 'os.pardir' (..) conforme a estrutura exata do seu diretório\n",
    "# os.pardir representa \"..\"\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir, os.pardir))\n",
    "\n",
    "# 3. Adiciona esse diretório ao caminho de busca do Python\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ee1b4a3-f9f9-4ba2-82e0-7e0e6c66cb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape depois da limpeza: (43678, 2)\n"
     ]
    }
   ],
   "source": [
    "from Lib.utils import printhello\n",
    "from Lib.utils import clean_text\n",
    "\n",
    "df['req_text_cleaned'] = df['req_text'].apply(lambda row_text: clean_text(\n",
    "        row_text, \n",
    "        do_lowercase=True, \n",
    "        rem_emails=True, \n",
    "        rem_urls=True, \n",
    "        normalize_whitespaces=True\n",
    "    ))\n",
    "\n",
    "df['req_text'] = df['req_text_cleaned']\n",
    "df = df.drop(columns=['req_text_cleaned']) # Remove a coluna temporária\n",
    "\n",
    "print(\"Shape depois da limpeza:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5b96b-658c-418e-9a06-eefd568892b1",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87920e4a-45a9-4a18-992e-9f244b4a5639",
   "metadata": {},
   "source": [
    "### Função de geração de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52c22d73-ab31-47cc-9b34-49a119c72c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embbed_generator(df, model: str):\n",
    "    embeddings_list = []\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    if model==\"BAAI-bge-3\":\n",
    "        print(\"Gerando BAAI embeddings\")\n",
    "        \n",
    "        embedding_model = SentenceTransformer('BAAI/bge-m3', device=device)\n",
    "        \n",
    "        embeddings_list = embedding_model.encode(df['req_text'].fillna(\"\").tolist())\n",
    "        print(f\"Shape dos embeddings (X): {embeddings_list.shape}\")\n",
    "    elif model==\"jiina-multilingual-v3\":\n",
    "        print(\"Gerando Jiina embeddings\")\n",
    "        embedding_model = SentenceTransformer(\"jinaai/jina-embeddings-v3\", trust_remote_code=True, device=device)\n",
    "        #embedding_model = SentenceTransformer(\"jinaai/jina-embeddings-v3-base-multilingual\", device=device)\n",
    "\n",
    "\n",
    "        embeddings_list = embedding_model.encode(df['req_text'].fillna(\"\").tolist())\n",
    "    elif model==\"gemma-300m\":\n",
    "        print(\"Gerando Gemma-300m embeddings\")\n",
    "        embedding_model = SentenceTransformer(\"google/embeddinggemma-300m\", device=device)\n",
    "\n",
    "        embeddings_list = embedding_model.encode_document(df['req_text'].fillna(\"\").tolist())\n",
    "\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd764b-ac00-4022-892f-285be248556f",
   "metadata": {},
   "source": [
    "### Geração e salvamento de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64fcf1e1-f401-447d-8db6-9ab4f81e08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_saving_path='./npys/embeddings_baai_bge3.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69cd5116-0f18-4c49-9edb-b996193c9a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando BAAI embeddings\n",
      "Shape dos embeddings (X): (43678, 1024)\n",
      "embeddings gerados\n",
      "embeddings salvos em ./npys/embeddings_baai_bge3.npy\n"
     ]
    }
   ],
   "source": [
    "# 1. Gerar os dados X e Y\n",
    "X_baai = embbed_generator(df, \"BAAI-bge-3\")\n",
    "\n",
    "print(\"embeddings gerados\")\n",
    "\n",
    "np.save(embeddings_saving_path, X_baai)\n",
    "print(f\"embeddings salvos em {embeddings_saving_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d83d70-817c-4871-8d56-a258deb95acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
