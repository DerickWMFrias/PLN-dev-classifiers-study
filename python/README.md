# DiretÃ³rio do EP de Processamento de Lingua Natural

Este documento se propÃµe a dar uma explicaÃ§Ã£o do cÃ³digo entregado e das tarefas desenvolvidas neste EP.

## Para avaliaÃ§Ã£o rÃ¡pida dos modelos de entrega

Os modelos da entrega do EP1 se encontram em:

- *EP1_best_arcaico_moderno.ipynb*: Entrega p/ dataset train_arcaico_moderno.csv
- *EP1_best_complexo_simples.ipynb*: Entrega p/ dataset train_complexo_simples.csv
- *EP1_best_literal_dinamico.ipynb*: Entrega p/ dataset train_literal_dinamico.csv

## Overview do projeto: Estrutura de diretÃ³rios

Neste diretÃ³rio temos o seguinte:
```
ğŸ“ python           #Dir atual
â”œâ”€â”€ Docs         #Documento de entrega do Trabalho
â”œâ”€â”€ Libs         #Codigo auxiliar desenvolvido
â”œâ”€â”€ Models       #Modelos treinados 
    â”œâ”€â”€ EP1
    â”œâ”€â”€ EP2
â””â”€â”€ Traindata    #Dados de treinamento do EP
    â”œâ”€â”€ EP1
    â”œâ”€â”€ EP2
â”œâ”€â”€ EP1_best_arcaico_moderno.ipynb  #Modelos com melhor acurÃ¡rica p/ dataset de treinos
â”œâ”€â”€ EP1_best_complexo_simples.ipynb
â”œâ”€â”€ EP1_best_literal_dinamico.ipynb
```

AlÃ©m disso, os diretÃ³rios */Models/EP**N*** contÃ©m um subdiretÃ³rio para cada instÃ¢ncia de dados de treinamento do EP, e ainda cada um desses diretÃ³rios contÃ©m um subdiretÃ³rio para cada modelo treinado. AlÃ©m disso, cada um desses diretÃ³rios de modelos contÃ©m dois notebooks: Um com as pipelines de treinamento e outro com a execuÃ§Ã£o do melhor modelo encontrado. Para compreender melhor, visualizemos: 


```
ğŸ“ Models/EP1
â”œâ”€â”€ ArcaicoModerno           #DiretÃ³rio com os modelos treinados p/ classificar em Arcaico/Moderno
    â”œâ”€â”€ LogisticRegression   #Treinamento de modelo RegressÃ£o LogÃ­stica
        â”œâ”€â”€ model.ipynb          #Melhor modelo obtido Ã  partir de pipeline.ipybn
        â”œâ”€â”€ pipeline.ipynb       #Pipelines de treinamento
    â”œâ”€â”€ NaiveBayes           #Treinamento de modelo Naive Bayes
        â”œâ”€â”€ model.ipynb
        â”œâ”€â”€ pipeline.ipynb
â”œâ”€â”€ ComplexoSimples 
    ...
```

## Modelos treinados

Nesta implementaÃ§Ã£o, cada dataset foi treinado sobre os modelos LinearRegression e NaiveBayes. As pipelines de treinamento utilizam *k-best* para seleÃ§Ã£o de atributos, e fazem otimizaÃ§Ã£o de hiperparÃ¢metros para cada modelo.

As features trabalhadas neste EP em cada pipeline sÃ£o:

1. Bag of Words
2. TF/TF-IDF
3. WORD NGrams
4. CHAR NGrams

### GeraÃ§Ã£o dos modelos de entrega

Configuradas as cÃ©lulas das pipelines de treinamento, cada cÃ©lula foi executada para encontrar os melhores parÃ¢metros - pela utilizaÃ§Ã£o de ***GridSearchCV*** parÃ¢metro de otimizaÃ§Ã£o *acurÃ¡cia* e utilizando *10-fold cross validation*.

Logo, para cada dataset de treinamento da entrega, a pipeline de um modelo treinado para essa entrega produz uma parametrizaÃ§Ã£o *otimal* de cada modelo, e entÃ£o comparamos a acurÃ¡cia de cada modelo - para encontrar a melhor parametrizaÃ§Ã£o gerada para aquele dataset. Essa parametrizaÃ§Ã£o que se encontra nos notebooks *EP1_best_arcaico_moderno.ipynb*, *EP1_best_complexo_simples.ipynb* e *EP1_best_literal_dinamico.ipynb*.

**PS**: A parametrizaÃ§Ã£o nÃ£o Ã© realmente *otimal* porque em nenhum caso testamos todas parametrizaÃ§Ãµes possiveis para nossos modelos, devido ao tempo/recursos dedicados. 


## DocumentaÃ§Ã£o Sugerida

A seguir estÃ£o algumas paginas de documentaÃ§Ã£o utilizadas na construÃ§Ã£o desse EP:

1. DocumentaÃ§Ã£o da API do ScikitLearn: https://scikit-learn.org/stable/api/index.html
2. How to work with text data in ScikitLearn: https://scikit-learn.org/1.4/tutorial/text_analytics/working_with_text_data.html 